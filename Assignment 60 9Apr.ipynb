{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c7c7a3-3d93-4b91-b096-143891ce45ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 1\n",
    "\n",
    "# Bayes’ theorem is a mathematical formula that describes the probability of an event, based on prior knowledge of conditions that might be related to the event.\n",
    "# It is named after Thomas Bayes, a statistician and philosopher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ebb299-c061-44a0-9658-0edd73804102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 2\n",
    "\n",
    "# he theorem is stated mathematically as the following equation:\n",
    "# P(A∣B)=fracP(B∣A)P(A)P(B)\n",
    "# where A and B are events and P(B)neq0. P(A∣B) is the probability of event A occurring given that event B has already occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88c768d5-b1db-40a9-8caa-9f1e24e5e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 3\n",
    "\n",
    "# Bayes’ theorem has many practical applications in various fields. Some of the most notable applications include:\n",
    "\n",
    "# Medical diagnosis: Bayes’ theorem is widely used in medical diagnosis, where the probability of a particular disease or condition given certain symptoms or test results is calculated.\n",
    "# It helps physicians assess the likelihood of a disease based on prior knowledge and test outcomes.\n",
    "# Spam filtering: In email spam filtering, Bayes’ theorem is used to classify incoming emails as spam or non-spam.\n",
    "# Machine learning: Bayes’ theorem finds wide application in applied machine learning and establishes a relationship between the data and a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8872a991-1c16-42be-8e17-8eeeddf4e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANs 4\n",
    "\n",
    "# Bayes’ theorem is a formula that describes how to update the probabilities of hypotheses when given evidence.\n",
    "# It follows simply from the axioms of conditional probability1. Conditional probability is an expression of how probable one event is given that some other event occurred.\n",
    "# For instance, “what is the probability that the sidewalk is wet?” will have a different answer than \"what is the probability that the sidewalk is wet given that it rained earlier?\".\n",
    "# Bayes’ theorem centers on relating different conditional probabilities. \n",
    "# Given a hypothesis H and evidence E, Bayes’ theorem states that the relationship between the probability of the hypothesis before getting the evidence P(H) \n",
    "# and the probability of the hypothesis after getting the evidence P(H∣E) is:\n",
    "# P(H∣E)=fracP(E∣H)P(E)P(H)\n",
    "# Many modern machine learning techniques rely on Bayes’ theorem. For instance, spam filters use Bayesian updating to determine whether an email is real or spam, \n",
    "# given the words in the email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5167812a-adaf-49c4-946e-bba588206cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANs 5\n",
    "\n",
    "# There are several types of Naive Bayes classifiers, and the choice of which one to use depends on the nature of the data and the problem at hand. \n",
    "# Some of the most popular types of Naive Bayes classifiers include:\n",
    "\n",
    "# Gaussian Naive Bayes: This type of Naive Bayes classifier is used when the variables are continuous in nature. It assumes that all the features follow a normal distribution.\n",
    "# Multinomial Naive Bayes: This type of Naive Bayes classifier is used when the features represent frequencies, such as in document classification.\n",
    "# Bernoulli Naive Bayes: This type of Naive Bayes classifier is used when the features are binary variables.\n",
    "# The choice of which type of Naive Bayes classifier to use depends on the nature of the data and the problem at hand. \n",
    "# For example, if you are working with continuous data that follows a normal distribution, you might choose to use a Gaussian Naive Bayes classifier. \n",
    "# n the other hand, if you are working with text data where the features represent word frequencies, you might choose to use a Multinomial Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd1db5-6eac-43aa-8dc0-5485714b6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 6\n",
    "\n",
    "# Given the data, we can use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. \n",
    "# Since the prior probabilities for each class are equal, we only need to calculate the likelihoods for each class.\n",
    "# The likelihood of class A given the new instance is calculated as follows:\n",
    "# P(X1=3∣A)∗P(X2=4∣A)=frac410∗frac313=frac12130\n",
    "# The likelihood of class B given the new instance is calculated as follows:\n",
    "# P(X1=3∣B)∗P(X2=4∣B)=frac15∗frac39=frac345\n",
    "# Since the likelihood of class A is greater than the likelihood of class B, Naive Bayes would predict that the new instance belongs to class A."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
